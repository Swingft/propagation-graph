import os
import json
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from functools import partial
from typing import List, Dict
from tqdm import tqdm

SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent

ANALYZER_DIR = PROJECT_ROOT / "SwiftASTAnalyzer"
TARGET_DATA_ROOT = PROJECT_ROOT / "data"
OUTPUT_ROOT = PROJECT_ROOT / "input_label"


NEW_PROMPT_CONTEXT = """Your Role: You are an expert static analysis assistant with a deep understanding of Swift's semantic structure. Your mission is to meticulously analyze the provided symbol information to identify which symbols must have their names preserved during code obfuscation and to clearly justify your reasoning.

Input Data:
The input is a JSON object containing symbol information generated by analyzing Swift source code. Each symbol includes a `symbol_id`, a `symbol_name`, and an `input` field containing the data for analysis.

Procedure:
1.  **Symbol-by-Symbol Analysis**: For every symbol provided, thoroughly examine the data within its `input` field.
2.  **Identify Exclusions**: Identify symbols that must be excluded from obfuscation based on clear evidence matching one or more of the **'Core Analysis Patterns'** below.
3.  **Generate Output**: For the identified exclusion candidates only, generate a result conforming to the **'Output Format'** rules. Symbols that can be safely obfuscated should not be included in the final output.

Core Analysis Patterns (Decision Criteria):
-   **Runtime String References** (`objc_selector`, `stringly_typed_api`): When a symbol's name is referenced as a string at runtime, such as with `#selector` or `Notification.Name`.
-   **KVC/KVO and Data Binding** (`kvc_kvo`, `coredata_nsmanaged`): When a name is depended upon by mechanisms like `@NSManaged`, Key-Value Coding/Observing, or `KeyPath`.
-   **C Function Interface (FFI) Exposure** (`ffi_entry`): When a symbol is exposed to external C code via attributes like `@_cdecl`.
-   **Reflection** (`runtime_reflection`): When property names are used dynamically at runtime through APIs like `Mirror`.
-   **Codable Synthesis** (`codable_synthesis`): When the compiler automatically uses property names as keys, for instance, in JSON encoding/decoding.
-   **Resource Binding** (`resource_binding`): When a name is linked to external resources like Storyboard IDs, XIBs, or Asset names.
-   **External Contracts and Extensions** (`external_contract`): When a symbol is part of a framework's Public API.
-   **Dynamic Dispatch & ObjC Exposure** (`dynamic_dispatch`, `objc_exposed`): When a symbol is a target for ObjC runtime features via `dynamic` or `@objc` attributes.
-   **Protocol Requirement Implementation** (`protocol_requirement`): When a symbol is an implementation of a protocol's required method, property, etc.

Output Format:
The result is a JSON object containing **only the symbols that must be excluded from obfuscation**. Each symbol must consist of the following fields:

-   `symbol_name`: The pure name **excluding function arguments**.
    -   (e.g., `performRequest((endpoint: String))` -> `performRequest`)
-   `tags`: An array of standard tags corresponding to the reason for exclusion.
-   `rationale`: A clear, 1-2 sentence explanation for the exclusion, based on the `input` data.

Example Final Output:
{
  "methods": [
    {
      "symbol_name": "updateConfiguration",
      "tags": [
        "kvo"
      ],
      "rationale": "This method is declared '@objc dynamic' and can be a target for KVO (Key-Value Observing), requiring its name to be preserved."
    }
  ],
  "properties": [
    {
      "symbol_name": "baseURL",
      "tags": [
        "kvo"
      ],
      "rationale": "This property is declared '@objc dynamic' and can be a target for KVO (Key-Value Observing), requiring its name to be preserved."
    }
  ],
  "structs": [],
  "enums": []
}
"""

KEY_MAPPING = {
    "is_protocol_requirement_impl": "p1",
    "codable_synthesized": "p2",
    "access_level": "p3",
    "is_ffi_entry": "p4",
    "override_depth": "p5",
    "modifiers": "p6",
    "is_coredata_nsmanaged": "p7",
    "ast_path": "p8",
    "cross_module_refs": "p9",
    "is_objc_exposed": "p10",
    "type_signature": "p11",
    "extension_file_count_same_name": "p12",
    "is_swiftdata_model": "p13",
    "symbol_kind": "p14",
    "references": "p15",
    "calls_out": "p16",
    "selector_refs": "p17",
    "attributes": "p18",
    "extension_of": "p19",
    "inherits": "p20",
    "conforms": "p21"
}

def build_analyzer(analyzer_dir: Path) -> Path:
    """SwiftASTAnalyzerë¥¼ ë¦´ë¦¬ì¦ˆ ëª¨ë“œë¡œ ë¹Œë“œí•˜ê³  ì‹¤í–‰ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("ğŸš€ SwiftASTAnalyzer ë¹Œë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    analyzer_bin_name = "swift-ast-analyzer"
    subprocess.run(
        ["swift", "build", "-c", "release"],
        cwd=analyzer_dir,
        check=True,
        capture_output=True,
        text=True,
    )
    print("âœ… ë¹Œë“œ ì™„ë£Œ!")
    analyzer_bin = analyzer_dir / ".build" / "release" / analyzer_bin_name
    if not analyzer_bin.exists():
        raise FileNotFoundError(f"ë¹Œë“œ í›„ì—ë„ ì‹¤í–‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {analyzer_bin}")
    return analyzer_bin


def find_swift_files(root: Path, target_dirs: List[str]) -> List[Path]:
    """ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  .swift íŒŒì¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    print("ğŸ” Swift íŒŒì¼ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    swift_files = []
    for dir_name in target_dirs:
        search_path = root / dir_name
        if search_path.is_dir():
            files_found = list(search_path.rglob("*.swift"))
            swift_files.extend(files_found)
            print(f"   - '{search_path}'ì—ì„œ {len(files_found)}ê°œì˜ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    print(f"âœ¨ ì´ {len(swift_files)}ê°œì˜ Swift íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return swift_files


def update_prompt_context(data: dict, new_context: str) -> dict:
    """JSON ë°ì´í„°ì˜ meta.prompt_context ê°’ì„ ìƒˆë¡œìš´ ë‚´ìš©ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤."""
    if 'meta' in data and isinstance(data['meta'], dict):
        data['meta']['prompt_context'] = new_context
    return data


def compact_input_keys(decisions_data: Dict, mapping: Dict) -> Dict:
    """'input' ê°ì²´ ë‚´ë¶€ì˜ í‚¤ë¥¼ ë§¤í•‘ì— ë”°ë¼ ê°„ê²°í•œ ì½”ë“œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not isinstance(decisions_data, dict):
        return decisions_data

    for category_list in decisions_data.values():
        if isinstance(category_list, list):
            for symbol_obj in category_list:
                if 'input' in symbol_obj and isinstance(symbol_obj['input'], dict):
                    original_input = symbol_obj['input']
                    compacted_input = {
                        mapping.get(key, key): value for key, value in original_input.items()
                    }
                    symbol_obj['input'] = compacted_input
    return decisions_data


def analyze_single_file(
        swift_file: Path, analyzer_bin: Path, data_root: Path, output_root: Path
):
    """ë‹¨ì¼ Swift íŒŒì¼ì„ ë¶„ì„í•˜ê³ , í‚¤ ê°„ê²°í™” ë° ì •ë¦¬ë¥¼ ìˆ˜í–‰í•œ í›„ JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        relative_path = swift_file.relative_to(data_root)
        output_dir = output_root / relative_path.parent
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"input_{swift_file.stem}.json"

        result = subprocess.run(
            [str(analyzer_bin), str(swift_file)],
            capture_output=True, text=True, check=True, encoding="utf-8",
        )

        original_data = json.loads(result.stdout)

        # 1. 'decisions' ë°ì´í„° ì¶”ì¶œ ë° í‚¤ ê°„ê²°í™”
        decisions_data = original_data.get('decisions', {})
        decisions_data = compact_input_keys(decisions_data, KEY_MAPPING)

        # 2. 'decisions' ë”•ì…”ë„ˆë¦¬ ë‚´ë¶€ ì •ë¦¬ (ë¹ˆ ë°°ì—´ ì†ì„± ë° ì¹´í…Œê³ ë¦¬ ì œê±°)
        if isinstance(decisions_data, dict):
            for category_list in decisions_data.values():
                if isinstance(category_list, list):
                    for symbol_obj in category_list:
                        if 'input' in symbol_obj and isinstance(symbol_obj['input'], dict):
                            keys_to_remove = [
                                key for key, value in symbol_obj['input'].items()
                                if isinstance(value, list) and not value
                            ]
                            for key in keys_to_remove:
                                del symbol_obj['input'][key]

            keys_to_remove = [
                key for key, value in decisions_data.items()
                if isinstance(value, list) and not value
            ]
            for key in keys_to_remove:
                del decisions_data[key]

        # 3. ìµœì¢… ì¶œë ¥ êµ¬ì¡° ìƒì„±
        final_output = {
            "mapping": KEY_MAPPING,
            "data": {
                "meta": original_data.get('meta', {}),
                "decisions": decisions_data
            }
        }

        # 4. prompt_context ì—…ë°ì´íŠ¸
        final_output['data'] = update_prompt_context(final_output['data'], NEW_PROMPT_CONTEXT)

        # 5. ìµœì¢… ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥
        cleaned_json_string = json.dumps(final_output, indent=2, ensure_ascii=False)
        output_file.write_text(cleaned_json_string, encoding="utf-8")

        return None

    except json.JSONDecodeError:
        return f"âŒ {swift_file} ë¶„ì„ ì‹¤íŒ¨: Swift ë¶„ì„ê¸°ê°€ ìœ íš¨í•œ JSONì„ ìƒì„±í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    except subprocess.CalledProcessError as e:
        return f"âŒ {swift_file} ë¶„ì„ ì‹¤íŒ¨:\n{e.stderr}"
    except Exception as e:
        return f"âŒ {swift_file} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ:\n{e}"


def main():
    try:
        analyzer_bin = build_analyzer(ANALYZER_DIR)
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        print(f"ğŸ”¥ ë¹Œë“œ ì‹¤íŒ¨: {e}")
        return

    target_dirs_to_scan = ["claude_generated", "gemini_generated"]
    swift_files = find_swift_files(TARGET_DATA_ROOT, target_dirs_to_scan)
    if not swift_files:
        print("âš ï¸ ë¶„ì„í•  Swift íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)
    print(f"\nâš™ï¸ ì´ {len(swift_files)}ê°œ íŒŒì¼ì— ëŒ€í•œ ë³‘ë ¬ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    worker_func = partial(
        analyze_single_file,
        analyzer_bin=analyzer_bin,
        data_root=TARGET_DATA_ROOT,
        output_root=OUTPUT_ROOT,
    )

    errors = []
    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
        results = list(tqdm(
            executor.map(worker_func, swift_files),
            total=len(swift_files),
            desc="íŒŒì¼ ë¶„ì„ ì¤‘"
        ))

    for res in results:
        if res is not None:
            errors.append(res)

    print("\n--- ë¶„ì„ ì™„ë£Œ ---")
    if not errors:
        print(f"ğŸ‰ ëª¨ë“  íŒŒì¼({len(swift_files)}ê°œ)ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print(f"ğŸ”¥ {len(errors)}ê°œì˜ íŒŒì¼ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:")
        for error_log in errors:
            print(error_log)


if __name__ == "__main__":
    main()
