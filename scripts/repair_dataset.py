import json
import os
from pathlib import Path
from typing import List, Dict, Any
from datasets import load_dataset


SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent
FINAL_DATASET_FILE = PROJECT_ROOT / "eval.jsonl"
REPAIRED_DATASET_FILE = PROJECT_ROOT / "alpaca_repaired.jsonl"


def fix_broken_jsonl(input_file: Path, output_file: Path) -> int:
    """
    JSONL íŒŒì¼ì„ ì½ì–´ ê° ì¤„ì˜ íŒŒì‹± ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ê³ , ìˆ˜ì •ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ íŒŒì¼ì— ì”ë‹ˆë‹¤.
    """
    print(f"âœ… '{input_file.name}' íŒŒì¼ì˜ ìë™ ë³µêµ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    fixed_records: List[Dict[str, Any]] = []
    issues_found = 0

    with input_file.open('r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue

            try:
                record = json.loads(line)
                fixed_records.append(record)

            except json.JSONDecodeError as e:
                issues_found += 1

                # ê°„ë‹¨í•œ ìë™ ìˆ˜ì • ì‹œë„: ëˆ„ë½ëœ ë‹«ëŠ” ë¬¸ì ì¶”ê°€
                fixed = False
                for fix in ['"', '}', '"}', '"]}', '"]}']:  # ë‹¤ì–‘í•œ ë‹«ëŠ” ë¬¸ì ì¡°í•© ì‹œë„
                    try:
                        fixed_line = line + fix
                        record = json.loads(fixed_line)
                        fixed_records.append(record)
                        print(f"ğŸ”§ ì¤„ {line_num}: '{fix}'ë¥¼ ì¶”ê°€í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {e})")
                        fixed = True
                        break
                    except json.JSONDecodeError:
                        continue  # í˜„ì¬ fix_charë¡œ ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ fix_char ì‹œë„

                if not fixed:
                    print(f"âš ï¸  ì¤„ {line_num}: ìˆ˜ì •í•  ìˆ˜ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤. (ë‚´ìš©: '{line[:75]}...' ì˜¤ë¥˜: {e})")

    if fixed_records:
        with output_file.open('w', encoding='utf-8') as f:
            for record in fixed_records:
                f.write(json.dumps(record, ensure_ascii=False) + '\n')

    print("\n--- ë³µêµ¬ ìš”ì•½ ---")
    print(f"ğŸ” ë°œê²¬ëœ ë¬¸ì œ: {issues_found}ê°œ")
    print(f"ğŸ’¾ ìœ íš¨í•œ ë ˆì½”ë“œ ì €ì¥: {len(fixed_records)}ê°œ")
    print(f"âœ¨ ë³µêµ¬ëœ íŒŒì¼ ìƒì„±: '{output_file}'")

    return len(fixed_records)


if __name__ == '__main__':
    if not FINAL_DATASET_FILE.exists():
        print(f"âŒ ì˜¤ë¥˜: ì›ë³¸ íŒŒì¼ '{FINAL_DATASET_FILE}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        record_count = fix_broken_jsonl(FINAL_DATASET_FILE, REPAIRED_DATASET_FILE)

        if record_count > 0:
            print("\n--- ë³µêµ¬ëœ íŒŒì¼ ê²€ì¦ ---")
            print("ğŸš€ ë³µêµ¬ëœ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
            try:
                dataset = load_dataset("json", data_files=str(REPAIRED_DATASET_FILE), split="train")
                print(f"ğŸ‰ ì„±ê³µ! ë³µêµ¬ëœ ë°ì´í„°ì…‹ì´ {len(dataset)}ê°œì˜ ë ˆì½”ë“œë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âŒ ê²€ì¦ ì‹¤íŒ¨! ë³µêµ¬ëœ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: {e}")
