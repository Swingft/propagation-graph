import json
import shutil
import multiprocessing
from pathlib import Path
from tqdm import tqdm
from typing import Dict


SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent

SOURCE_INPUT_ROOT = PROJECT_ROOT / 'llm_training_inputs'
SPLIT_DATA_ROOT = PROJECT_ROOT / 'llm_training_data_split'
SPLIT_INPUT_ROOT = SPLIT_DATA_ROOT / 'inputs'

CONTEXT_MAP = {
    'methods': ['methods', 'initializers', 'deinitializers', 'subscripts', 'variables'],
    'properties': ['properties'],
    'variables': ['variables'],
    'initializers': ['classes', 'structs', 'enums', 'protocols', 'extensions', 'initializers'],
    'deinitializers': ['classes', 'structs', 'enums', 'protocols', 'extensions', 'deinitializers'],
    'subscripts': ['classes', 'structs', 'enums', 'protocols', 'extensions', 'subscripts'],
    'enumCases': ['enums', 'enumCases'],
    'classes': ['classes', 'protocols', 'structs'],
    'structs': ['structs', 'protocols', 'classes'],
    'enums': ['enums', 'protocols', 'enumCases', 'classes'],
    'protocols': ['protocols'],
    'extensions': ['extensions', 'classes', 'structs', 'enums', 'protocols'],
    'typealiases': ['typealiases', 'classes', 'structs', 'enums', 'protocols', 'extensions']
}


def setup_directories():
    """ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤."""
    print("ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")
    if SPLIT_DATA_ROOT.exists():
        shutil.rmtree(SPLIT_DATA_ROOT)
    SPLIT_INPUT_ROOT.mkdir(parents=True, exist_ok=True)
    print("ë””ë ‰í† ë¦¬ ì¤€ë¹„ ì™„ë£Œ.")


def split_single_input_file(file_path: Path):
    """
    í•˜ë‚˜ì˜ ì›ë³¸ input íŒŒì¼ì„ CONTEXT_MAP ê·œì¹™ì— ë”°ë¼ ì—¬ëŸ¬ ê°œì˜ ì‘ì€ input íŒŒì¼ë¡œ ë¶„í• í•˜ê³ ,
    ìƒì„±ëœ íŒŒì¼ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        created_files_count = 0
        instruction = data.get("instruction")
        original_input = data.get("input", {})
        original_symbols = original_input.get("symbol_data_for_analysis", {})

        base_name = file_path.stem.replace('training_input_', '')
        relative_parent = file_path.relative_to(SOURCE_INPUT_ROOT).parent

        for group_name, source_categories in CONTEXT_MAP.items():
            # 1. ë¶„í• ëœ Input ë°ì´í„° ìƒì„±
            grouped_input_symbols = {}
            for category in source_categories:
                if category in original_symbols:
                    grouped_input_symbols[category] = original_symbols[category]

            # ê·¸ë£¹ì— í•´ë‹¹í•˜ëŠ” ì‹¬ë³¼ì´ ì—†ìœ¼ë©´ ì´ ê·¸ë£¹ì€ ê±´ë„ˆëœ€
            if not grouped_input_symbols:
                continue

            # 2. ìƒˆë¡œìš´ Input ê°ì²´ êµ¬ì„±
            new_input_obj = original_input.copy()
            new_input_obj['symbol_data_for_analysis'] = grouped_input_symbols

            final_input_record = {
                "instruction": instruction,
                "input": new_input_obj,
                "output": ""  # Output í•„ë“œëŠ” ë¹„ì›Œë‘ 
            }

            # 3. ë¶„í• ëœ íŒŒì¼ ì €ì¥
            group_dir_name = f"{group_name}_group"
            input_save_dir = SPLIT_INPUT_ROOT / relative_parent / group_dir_name
            input_save_dir.mkdir(parents=True, exist_ok=True)
            input_filename = f"input_{base_name}_{group_dir_name}.json"

            with open(input_save_dir / input_filename, 'w', encoding='utf-8') as f:
                json.dump(final_input_record, f, indent=2, ensure_ascii=False)

            created_files_count += 1

        return created_files_count
    except Exception as e:
        return f"ì˜¤ë¥˜: {file_path.name} ì²˜ë¦¬ ì¤‘ - {e}"


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    setup_directories()

    source_files = sorted(list(SOURCE_INPUT_ROOT.rglob("*.json")))
    if not source_files:
        print("ë¶„í• í•  ì›ë³¸ ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nğŸš€ ì´ {len(source_files)}ê°œì˜ ì›ë³¸ ì…ë ¥ íŒŒì¼ì„ ë¶„í• í•©ë‹ˆë‹¤...")

    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        results = list(
            tqdm(pool.imap_unordered(split_single_input_file, source_files), total=len(source_files),
                 desc="Input íŒŒì¼ ë¶„í•  ì¤‘"))

    errors = []
    total_split_files_created = 0
    for res in results:
        if isinstance(res, int):
            total_split_files_created += res
        elif isinstance(res, str):
            errors.append(res)

    print("\nğŸ‰ ë¶„í•  ì‘ì—… ì™„ë£Œ!")
    if errors:
        print(f"   - {len(errors)}ê°œì˜ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        for err in errors[:5]:
            print(f"     - {err}")

    print(f"   - ì´ {total_split_files_created}ê°œì˜ ë¶„í• ëœ input íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   - ê²°ê³¼ëŠ” '{SPLIT_INPUT_ROOT}' í´ë”ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


if __name__ == '__main__':
    main()

